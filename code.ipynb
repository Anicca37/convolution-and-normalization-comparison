{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJaKDVNjPjr-"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-LnUnjQbdLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf04a37a-c55e-4e6d-a136-1d62c834160b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f950568a9b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from functools import partial\n",
        "from typing import Any, Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(37)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxHGAhqtbuM7"
      },
      "source": [
        "# Seperable Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation of DepthwiseConv2D, PointwiseConv2D and SeparableConv2D."
      ],
      "metadata": {
        "id": "aA5ROH-P_Gyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSq6vINcJDZJ"
      },
      "outputs": [],
      "source": [
        "class DepthwiseConv2D(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True,\n",
        "                 padding_mode='zeros',\n",
        "                 device=None,\n",
        "                 dtype=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.depthwise_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                        out_channels=out_channels,\n",
        "                                        kernel_size=kernel_size,\n",
        "                                        stride=stride,\n",
        "                                        padding=padding,\n",
        "                                        dilation=dilation,\n",
        "                                        groups=groups,\n",
        "                                        bias=bias,\n",
        "                                        padding_mode=padding_mode,\n",
        "                                        device=device,\n",
        "                                        dtype=dtype)\n",
        "        \n",
        "        ########################################################################\n",
        "        # Below we can add a batch norm or group norm layer to DepthwiseConv2D #\n",
        "        ########################################################################\n",
        "        # self.bn = nn.BatchNorm2d(out_channels)\n",
        "        # self.gn = nn.GroupNorm(16, out_channels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.depthwise_conv(x)\n",
        "        return x\n",
        "        \n",
        "        ########################################################################\n",
        "        # Below we can add a batch norm or group norm layer to DepthwiseConv2D #\n",
        "        ########################################################################        \n",
        "        # return self.bn(x)\n",
        "        # return self.gn(x)\n",
        "\n",
        "\n",
        "class PointwiseConv2D(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 bias=True,\n",
        "                 device=None,\n",
        "                 dtype=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.pointwise_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                        out_channels=out_channels,\n",
        "                                        kernel_size=(1, 1),\n",
        "                                        stride=1,\n",
        "                                        padding=0,\n",
        "                                        dilation=1,\n",
        "                                        groups=1,\n",
        "                                        bias=bias,\n",
        "                                        padding_mode='zeros',\n",
        "                                        device=device,\n",
        "                                        dtype=dtype)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pointwise_conv(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "class SeparableConv2D(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 bias=True,\n",
        "                 padding_mode='zeros',\n",
        "                 device=None,\n",
        "                 dtype=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = self.depthwise_conv = DepthwiseConv2D(in_channels=in_channels,\n",
        "                                              out_channels=in_channels,\n",
        "                                              kernel_size=kernel_size,\n",
        "                                              stride=stride,\n",
        "                                              padding=padding,\n",
        "                                              dilation=dilation,\n",
        "                                              groups=in_channels,\n",
        "                                              bias=bias,\n",
        "                                              padding_mode=padding_mode,\n",
        "                                              device=device,\n",
        "                                              dtype=dtype)\n",
        "\n",
        "        self.layer2 = self.pointwise_conv = PointwiseConv2D(in_channels=in_channels,\n",
        "                                              out_channels=out_channels,\n",
        "                                              bias=bias,\n",
        "                                              device=device,\n",
        "                                              dtype=dtype)\n",
        "        self.seperable = nn.Sequential(self.layer1, self.layer2)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.seperable(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecNXjx-MPrVI"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwOxCUPUSInn"
      },
      "source": [
        "## AlexNet(Normal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9ts_qlURfqQ"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=9216, out_features=4096)\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "  \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRGrE0GecBZL"
      },
      "source": [
        "## AlexNet(SeparableConv2D + BN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqZ1NgLrcATy"
      },
      "outputs": [],
      "source": [
        "class AlexNet_S(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet_S, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(96, eps=0.001)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(256, eps=0.001)\n",
        "        self.conv3 = SeparableConv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(384, eps=0.001)\n",
        "        self.conv4 = SeparableConv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(384, eps=0.001)\n",
        "        self.conv5 = SeparableConv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256, eps=0.001)\n",
        "        self.fc1 = nn.Linear(in_features=9216, out_features=4096)\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.bn1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.bn4(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.bn5(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "   \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HNrog4jBYsC"
      },
      "source": [
        "## AlexNet(SeperableConv2D + GN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN3Gl0A7ByI4"
      },
      "outputs": [],
      "source": [
        "class AlexNet_L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet_L, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "        self.gn1 = nn.GroupNorm(16, 96, eps=0.001)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
        "        self.gn2 = nn.GroupNorm(16, 256, eps=0.001)\n",
        "        self.conv3 = SeparableConv2D(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.gn3 = nn.GroupNorm(16, 384, eps=0.001)\n",
        "        self.conv4 = SeparableConv2D(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.gn4 = nn.GroupNorm(16, 384, eps=0.001)\n",
        "        self.conv5 = SeparableConv2D(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.gn5 = nn.GroupNorm(16, 256, eps=0.001)\n",
        "        self.fc1 = nn.Linear(in_features=9216, out_features=4096)\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.gn1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.gn2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.gn3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.gn4(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.gn5(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "   \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqBWl2OtQLZH"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuprL5FuaRcs"
      },
      "source": [
        "## VGG-16(Normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSIC579DaPx7"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(25088, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YHx8Zyvnlh"
      },
      "source": [
        "## VGG-16(SeperableConv2D + BN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DikZHw5PvmVB"
      },
      "outputs": [],
      "source": [
        "class VGG16_S(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16_S, self).__init__()\n",
        "        self.conv1_1 = SeparableConv2D(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(64, eps=0.001)\n",
        "        self.conv1_2 = SeparableConv2D(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64, eps=0.001)\n",
        "\n",
        "        self.conv2_1 = SeparableConv2D(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(128, eps=0.001)\n",
        "        self.conv2_2 = SeparableConv2D(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128, eps=0.001)\n",
        "\n",
        "        self.conv3_1 = SeparableConv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(256, eps=0.001)\n",
        "        self.conv3_2 = SeparableConv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256, eps=0.001)\n",
        "        self.conv3_3 = SeparableConv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn3_3 = nn.BatchNorm2d(256, eps=0.001)\n",
        "\n",
        "        self.conv4_1 = SeparableConv2D(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(512, eps=0.001)\n",
        "        self.conv4_2 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(512, eps=0.001)\n",
        "        self.conv4_3 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn4_3 = nn.BatchNorm2d(512, eps=0.001)\n",
        "\n",
        "        self.conv5_1 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(512, eps=0.001)\n",
        "        self.conv5_2 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn5_2 = nn.BatchNorm2d(512, eps=0.001)\n",
        "        self.conv5_3 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.bn5_3 = nn.BatchNorm2d(512, eps=0.001)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(25088, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = self.bn1_1(x)\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.bn1_2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = self.bn2_1(x)\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.bn2_2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = self.bn3_1(x)\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = self.bn3_2(x)\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = self.bn3_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = self.bn4_1(x)\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = self.bn4_2(x)\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = self.bn4_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = self.bn5_1(x)\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = self.bn5_2(x)\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        x = self.bn5_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx5LJXOXFlu2"
      },
      "source": [
        "## VGG-16(SeperableConv2D + GN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHKd1C9SFtrn"
      },
      "outputs": [],
      "source": [
        "class VGG16_L(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16_L, self).__init__()\n",
        "        self.conv1_1 = SeparableConv2D(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.gn1_1 = nn.GroupNorm(16, 64, eps=0.001)\n",
        "        self.conv1_2 = SeparableConv2D(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.gn1_2 = nn.GroupNorm(16, 64, eps=0.001)\n",
        "\n",
        "        self.conv2_1 = SeparableConv2D(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.gn2_1 = nn.GroupNorm(16, 128, eps=0.001)\n",
        "        self.conv2_2 = SeparableConv2D(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.gn2_2 = nn.GroupNorm(16, 128, eps=0.001)\n",
        "\n",
        "        self.conv3_1 = SeparableConv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.gn3_1 = nn.GroupNorm(16, 256, eps=0.001)\n",
        "        self.conv3_2 = SeparableConv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.gn3_2 = nn.GroupNorm(16, 256, eps=0.001)\n",
        "        self.conv3_3 = SeparableConv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.gn3_3 = nn.GroupNorm(16, 256, eps=0.001)\n",
        "\n",
        "        self.conv4_1 = SeparableConv2D(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn4_1 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "        self.conv4_2 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn4_2 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "        self.conv4_3 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn4_3 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "\n",
        "        self.conv5_1 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn5_1 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "        self.conv5_2 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn5_2 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "        self.conv5_3 = SeparableConv2D(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.gn5_3 = nn.GroupNorm(16, 512, eps=0.001)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(25088, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = self.gn1_1(x)\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = self.gn1_2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = self.gn2_1(x)\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = self.gn2_2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = self.gn3_1(x)\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = self.gn3_2(x)\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = self.gn3_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = self.gn4_1(x)\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = self.gn4_2(x)\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = self.gn4_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv5_1(x))\n",
        "        x = self.gn5_1(x)\n",
        "        x = F.relu(self.conv5_2(x))\n",
        "        x = self.gn5_2(x)\n",
        "        x = F.relu(self.conv5_3(x))\n",
        "        x = self.gn5_3(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, 0.5)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-q0U_plR9Mt"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U74XLUbyKKzn"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, test_loader, device):\n",
        "    \n",
        "    # loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                 lr= 1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15], gamma=0.1)\n",
        "    \n",
        "    training_losses = []\n",
        "    training_acc = []\n",
        "    training_time = []\n",
        "    test_losses = []\n",
        "    test_acc = []\n",
        "    test_time = []\n",
        "\n",
        "    for epoch in range(20):\n",
        "\n",
        "      # train\n",
        "      model.train()\n",
        "      losses = 0.0\n",
        "      \n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      start_time = time.time()\n",
        "      for _, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimizer + scheduler\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses += loss.item()\n",
        "\n",
        "        _, predictions = outputs.max(1)\n",
        "        correct += (predictions == labels).sum()\n",
        "        total += predictions.size(0)\n",
        "      \n",
        "      tr_time = time.time() - start_time\n",
        "      training_time.append(tr_time)\n",
        "      avg_train_loss = losses / len(train_loader)\n",
        "      training_losses.append(avg_train_loss)\n",
        "      tr_acc = float(correct) / float(total) * 100\n",
        "      training_acc.append(tr_acc)\n",
        "      \n",
        "      print(f\"Epoch: {epoch+1}\")\n",
        "      print(\"Average training loss: %.4f, Accuracy : %.2f%%, Time(s): %.2f\"\n",
        "            % (avg_train_loss, tr_acc, tr_time))\n",
        "\n",
        "        \n",
        "      # evaluate on the 10,000 test images\n",
        "      model.eval()\n",
        "      losses = 0.0\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for _, (inputs, labels) in enumerate(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            losses += loss.item()\n",
        "\n",
        "            _, predictions = outputs.max(1)\n",
        "            correct += (predictions == labels).sum()\n",
        "            total += predictions.size(0)\n",
        "\n",
        "        te_time = time.time() - start_time\n",
        "        test_time.append(te_time)\n",
        "        avg_test_loss = losses / len(test_loader)\n",
        "        test_losses.append(avg_test_loss)\n",
        "        te_acc = float(correct) / float(total) * 100\n",
        "        test_acc.append(te_acc)\n",
        "\n",
        "        # change learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\"Average test loss: %.4f, Accuracy : %.2f%%, Time(s): %.2f\"\n",
        "              % (avg_test_loss, te_acc, te_time))\n",
        "\n",
        "    # plot\n",
        "    epochs = [i for i in range(1, 21)]\n",
        "    plt.plot(epochs, training_losses, \"mediumseagreen\", label=\"training_losses\")\n",
        "    plt.plot(epochs, test_losses, \"mediumpurple\", label=\"test_losses\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.savefig(\"losses.png\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epochs, training_acc, \"mediumseagreen\", label=\"training_accuracy\")\n",
        "    plt.plot(epochs, test_acc, \"mediumpurple\", label=\"test_accuracy\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.savefig(\"accuracy.png\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epochs, training_time, \"mediumseagreen\", label=\"training_time\")\n",
        "    plt.plot(epochs, test_time, \"mediumpurple\", label=\"test_time\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"time\")\n",
        "    plt.savefig(\"time.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkd964WcROjT"
      },
      "source": [
        "## CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LpYPKZku5G9"
      },
      "source": [
        "Below, we test different models on CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aHoY2PP3-6wK"
      },
      "outputs": [],
      "source": [
        "# load CIFAR-10 dataset\n",
        "transform_train = transforms.Compose([transforms.Resize((227,227)), \n",
        "                                      transforms.RandomHorizontalFlip(p=0.7), \n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                           std=[0.229, 0.224, 0.225])])\n",
        "transform_test = transforms.Compose([transforms.Resize((227,227)), \n",
        "                                     transforms.ToTensor(), \n",
        "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                          std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data = datasets.CIFAR10(\n",
        "    root='./data', \n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n",
        "\n",
        "# train\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# AlexNet(Normal)\n",
        "# model1 = AlexNet()\n",
        "# model1.to(device)\n",
        "# train(model1, train_loader, test_loader, device)\n",
        "\n",
        "# AlexNet(SeparableConv2D + BN)\n",
        "# model2 = AlexNet_S()\n",
        "# model2.to(device)\n",
        "# train(model2, train_loader, test_loader, device)\n",
        "\n",
        "# AlexNet(SeparableConv2D + GN)\n",
        "# model3 = AlexNet_L()\n",
        "# model3.to(device)\n",
        "# train(model3, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16(Normal)\n",
        "# model4 = VGG16()\n",
        "# model4.to(device)\n",
        "# train(model4, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16(SeparableConv2D + BN)\n",
        "# model5 = VGG16_S()\n",
        "# model5.to(device)\n",
        "# train(model5, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16L(SeparableConv2D + GN)\n",
        "# model6 = VGG16_L()\n",
        "# model6.to(device)\n",
        "# train(model6, train_loader, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dIO0lZaRWDD"
      },
      "source": [
        "## STL10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8TqRAu8RqGg"
      },
      "source": [
        "Below, we test different models on MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtbI-bvNRwRw"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((227,227)), \n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data = datasets.STL10(\n",
        "    root='./data', \n",
        "    split='train',\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "test_data = datasets.STL10(\n",
        "    root='./data',\n",
        "    split='test',\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2)\n",
        "\n",
        "# train\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# AlexNet(Normal)\n",
        "# model1 = AlexNet()\n",
        "# model1.to(device)\n",
        "# train(model1, train_loader, test_loader, device)\n",
        "\n",
        "# AlexNet(SeparableConv2D + BN)\n",
        "# model2 = AlexNet_S()\n",
        "# model2.to(device)\n",
        "# train(model2, train_loader, test_loader, device)\n",
        "\n",
        "# AlexNet(SeparableConv2D + GN)\n",
        "# model3 = AlexNet_L()\n",
        "# model3.to(device)\n",
        "# train(model3, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16(Normal)\n",
        "# model4 = VGG16()\n",
        "# model4.to(device)\n",
        "# train(model4, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16(SeperableConv2D + BN)\n",
        "# model5 = VGG16_S()\n",
        "# model5.to(device)\n",
        "# train(model5, train_loader, test_loader, device)\n",
        "\n",
        "# VGG-16(SeperableConv2D + GN)\n",
        "# model6 = VGG16_L()\n",
        "# model6.to(device)\n",
        "# train(model6, train_loader, test_loader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CxHGAhqtbuM7",
        "MwOxCUPUSInn",
        "sRGrE0GecBZL",
        "DuprL5FuaRcs",
        "K5YHx8Zyvnlh"
      ],
      "machine_shape": "hm",
      "name": "CSC413-project-FINAL-VERSION.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}